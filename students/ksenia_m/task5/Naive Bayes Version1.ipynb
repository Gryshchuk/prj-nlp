{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kseniia/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_set = pd.read_csv('./collectdata/comments_ua.txt', sep = ':::::', names = [\"score\", \"comment\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment\n",
       "score         \n",
       "1           70\n",
       "2           84\n",
       "3          171\n",
       "4          605\n",
       "5         2196"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.groupby(\"score\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(data_set)) < 0.8\n",
    "train = data_set[msk]\n",
    "test = data_set[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(**kwargs):\n",
    "    \n",
    "    def calc_probabilities_in_class(data):\n",
    "        bag_of_words = {}\n",
    "        for index, row in data.iterrows():\n",
    "            words = nltk.word_tokenize(row['comment'])\n",
    "            for word in words:\n",
    "                word_l = word.lower()\n",
    "                if not word_l in bag_of_words:\n",
    "                    bag_of_words[word_l] = 1\n",
    "                else:\n",
    "                    bag_of_words[word_l] = bag_of_words[word_l] + 1\n",
    "        return bag_of_words\n",
    "    \n",
    "    probabilities = {}\n",
    "    for key in kwargs:\n",
    "        probabilities[key] = calc_probabilities_in_class(kwargs[key])\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def predict_model_comment(model, comment):\n",
    "    \n",
    "    def comment_log_probabitlity(words, class_model, total_words, total_unique_words):\n",
    "        denominator = sum(class_model.values()) + total_unique_words\n",
    "        log_prob = math.log(sum(class_model.values()) / total_words)\n",
    "        for word in words:\n",
    "            n = class_model[word] if word in class_model else 0 \n",
    "            log_prob += math.log((n + 1)/denominator)\n",
    "        return log_prob\n",
    "        \n",
    "    log_probablitites = {}\n",
    "    words = nltk.word_tokenize(comment)\n",
    "    \n",
    "    total_words = 0\n",
    "    total_unique_words = 0\n",
    "    for key in model:\n",
    "        total_words += sum(model[key].values())\n",
    "        total_unique_words += len(model[key])\n",
    "        \n",
    "    for key in model:\n",
    "        log_probablitites[key] = comment_log_probabitlity(words, model[key], total_words, total_unique_words)\n",
    "    return log_probablitites\n",
    "\n",
    "def print_report(true_positive, true_negative, false_positive, false_negative):\n",
    "    print(\"True Positive:\", true_positive, \"; True negative:\", \n",
    "          true_negative, \"; False positive:\", false_positive, \"; False negative:\", false_negative)\n",
    "    print(\"Presision:\", true_positive/(true_positive + false_positive),\n",
    "          \"; Recall:\", true_positive/(true_positive + false_negative))\n",
    "\n",
    "def predict_on_set(predict_comment_lambda, test_set, labeled_negative):\n",
    "    \n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    for index, row in test_set.iterrows():\n",
    "        max_prob = float('-inf')\n",
    "        max_key = \"\"\n",
    "        probs = predict_comment_lambda(row[\"comment\"])\n",
    "        for key_class in probs:\n",
    "            if probs[key_class] > max_prob:\n",
    "                max_prob = probs[key_class]\n",
    "                max_key = key_class\n",
    "        is_negative_eval = max_key == 'negative'\n",
    "        is_negative_label = labeled_negative(row[\"score\"]) \n",
    "        #print(\"is_negative_eval:\", is_negative_eval, \" is_neg_label:\", is_negative_label)\n",
    "      \n",
    "        if is_negative_eval and is_negative_label:\n",
    "            true_negative += 1\n",
    "            \n",
    "        if not is_negative_eval and not is_negative_label:\n",
    "            true_positive += 1\n",
    "            \n",
    "        if not is_negative_eval and is_negative_label:\n",
    "            false_positive += 1\n",
    "            \n",
    "        if is_negative_eval and not is_negative_label:\n",
    "            false_negative += 1\n",
    "        \n",
    "    return print_report(true_positive, true_negative, false_positive, false_negative)\n",
    "        \n",
    "def predict_random_comment(train_data, comment):\n",
    "    total_positive = train_data[train_data[\"score\"] > 3][\"comment\"].count()\n",
    "    positive_prob = total_positive / train_data[\"comment\"].count()\n",
    "\n",
    "    if random.random() > positive_prob:\n",
    "        return {\"positive\": 0, \"negative\": 1}\n",
    "    return {\"positive\": 1, \"negative\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pure model (no rules or sentiment dictionary) and compare it with random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For pure model:\n",
      "True Positive: 506 ; True negative: 16 ; False positive: 48 ; False negative: 48\n",
      "Presision: 0.9133574007220217 ; Recall: 0.9133574007220217\n",
      "For random:\n",
      "True Positive: 495 ; True negative: 8 ; False positive: 56 ; False negative: 59\n",
      "Presision: 0.8983666061705989 ; Recall: 0.8935018050541517\n"
     ]
    }
   ],
   "source": [
    "model = train_model(positive = train[train[\"score\"] > 3], negative = train[train[\"score\"] <= 3])\n",
    "print(\"For pure model:\")\n",
    "predict_on_set(lambda comment: predict_model_comment(model, comment), test, lambda x: x <= 3)\n",
    "print(\"For random:\")\n",
    "predict_on_set(lambda comment: predict_random_comment(train, comment), test, lambda x: x <= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check classifier from nltk\n",
    "all_words = set(word.lower() for index,row in train.iterrows() for word in nltk.word_tokenize(row[\"comment\"]))\n",
    "train_as_words = [({word: (word in nltk.word_tokenize(row[\"comment\"])) for word in all_words},\n",
    "                   \"negative\" if row[\"score\"] <= 3 else \"positive\")  for index,row in train.iterrows()]\n",
    "print(train_as_words[0:10])\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_as_words)\n",
    "classifier.show_most_informative_features()\n",
    "    \n",
    "def prdic_by_nltk(comment):\n",
    "    global all_words\n",
    "    global classifier\n",
    "    test_sent_features = {word.lower(): (word in nltk.word_tokenize(comment.lower())) for word in all_words}\n",
    "    label = classifier.classify(test_sent_features)\n",
    "    return {\"positive\": (1 if label == \"positive\" else 0), \"negative\": (1 if label == \"negative\" else 0)}\n",
    "\n",
    "predict_on_set(prdic_by_nltk, test, lambda x: x <= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 520 ; True negative: 9 ; False positive: 55 ; False negative: 34\n",
      "Presision: 0.9043478260869565 ; Recall: 0.9386281588447654\n",
      "365\n"
     ]
    }
   ],
   "source": [
    "tonal_dict = pd.read_csv('../../../../sources/tone-dict-uk.tsv', sep = '\\t', names = [\"word\", \"sentiment\"])\n",
    "\n",
    "def predict_comment_with_tonal(model, comment):\n",
    "    \n",
    "    def sentiment_score():\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        for index, row in tonal_dict.iterrows():\n",
    "            if row[\"word\"] in comment:\n",
    "                if int(row[\"sentiment\"]) > 0:\n",
    "                    positive += int(row[\"sentiment\"])\n",
    "                else:\n",
    "                    negative += int(row[\"sentiment\"])\n",
    "        return positive if positive > -negative else negative\n",
    "            \n",
    "    score = sentiment_score()\n",
    "   \n",
    "    if score > 0:\n",
    "        return {\"positive\": 1, \"negative\":0}\n",
    "    if score < 0:\n",
    "        return {\"negative\": 0, \"positive\":1}\n",
    "    \n",
    "    return predict_model_comment(model, comment)\n",
    "    \n",
    "predict_on_set(lambda comment: predict_comment_with_tonal(model, comment), test, lambda x: x <= 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['і', 'на', '.', ',', 'в', '(', ')', 'а', 'за', 'у']\n",
    "for key in model['negative']:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
