{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Associated Press Stylebook is a style guide widely used among American journalists. It enforces the following rules for capitalization of news headlines:\n",
    "\n",
    "Capitalize nouns, pronouns, adjectives, verbs, adverbs, and subordinate conjunctions. If a word is hyphenated, every part of the word should be capitalized (e.g., \"Self-Reflection\" not \"Self-reflection\").\n",
    "Capitalize the first and the last word.\n",
    "Lowercase all other parts of speech: articles, coordinating conjunctions, prepositions, particles, interjections.\n",
    "Write a program that formats a headline according to the rules above. Use any programming language and any NLP toolkit.\n",
    "\n",
    "When done, run your program on the corpus of headlines from The Examiner and submit your program and a file with corrected headlines to your directory. Output statistics: how many titles were properly formatted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('examiner-headlines.txt', encoding='utf8') as f:\n",
    "    content = f.readlines()\n",
    "headlines = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "class HeaderMaker:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en')\n",
    "        \n",
    "    #capitalized_rules\n",
    "    def capitalize(self, word):\n",
    "        res= word[0].upper()\n",
    "        for i in range(1, len(word)):\n",
    "            next_char = word[i] \n",
    "            if (word[i-1]=='-') or (((i+1)<len(word)) and (word[i+1]=='-')):\n",
    "                next_char=next_char.upper()\n",
    "            res=res+next_char\n",
    "        return res\n",
    "    #print(capitalize('a a-a---a bcd'))\n",
    "\n",
    "    #Capitalize nouns, pronouns, adjectives, verbs, adverbs, and subordinate conjunctions.\n",
    "    def part_of_speach_rule(self, token, sent):\n",
    "        pos_tags=['NOUN','PRON','PROPN','ADJ','VERB','ADV','SCONJ']\n",
    "        return token.pos_ in pos_tags\n",
    "    \n",
    "    #If a word is hyphenated, every part of the word should be capitalized (e.g., \"Self-Reflection\" not \"Self-reflection\").\n",
    "    def hyphen_rule(self, token, sent):\n",
    "        return '-' in token.text\n",
    "    \n",
    "    #Capitalize the first and the last word.\n",
    "    def first_last_word_rule(self, token, sent):\n",
    "        return (token.idx==0) or ((token.idx+len(token.text))==len(sent))\n",
    "\n",
    "    def rule_list(self, token, sent):\n",
    "        rules = [self.hyphen_rule,self.first_last_word_rule,self.part_of_speach_rule]\n",
    "        for rule in rules:\n",
    "            if rule(token, sent):\n",
    "                return rule.__name__\n",
    "        return 'lower_case'\n",
    "    \n",
    "    def process(self, sent):\n",
    "        parsed_sentence = self.nlp(sent)\n",
    "        info = {}\n",
    "        new_title=\"\"\n",
    "        validation_errors=[]\n",
    "        for token in parsed_sentence:\n",
    "            item ={}\n",
    "            item['rule']=self.rule_list(token,sent)\n",
    "            item['correct_text']=capitalize(token.text) if item['rule']!='lower_case' else token.text.lower()\n",
    "            item['is_correct']=token.text == item['correct_text']\n",
    "            info[token]=item\n",
    "            \n",
    "            if item['is_correct']==False:\n",
    "                validation_errors.append(item['rule'])\n",
    "            \n",
    "            corect_word = token.text_with_ws.replace(token.text, item['correct_text'])\n",
    "            new_title=new_title+corect_word\n",
    "        return new_title, validation_errors, len(validation_errors)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talladega turmoil could spell trouble for NASCAR's Chase field\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"Talladega Turmoil Could Spell Trouble for NASCAR's Chase Field\",\n",
       " ['part_of_speach_rule',\n",
       "  'part_of_speach_rule',\n",
       "  'part_of_speach_rule',\n",
       "  'part_of_speach_rule',\n",
       "  'first_last_word_rule'],\n",
       " False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maker =HeaderMaker()\n",
    "sent = \"Talladega turmoil could spell trouble for NASCAR's Chase field\"\n",
    "print(sent)\n",
    "maker.process(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_headlines=[]\n",
    "all_errors=[]\n",
    "correct_titles=0\n",
    "maker =HeaderMaker()\n",
    "for sent in headlines:\n",
    "    correct_title, errors, is_correct =  maker.process(sent)\n",
    "    correct_titles= correct_titles+int(is_correct)\n",
    "    all_errors=all_errors+errors\n",
    "    new_headlines.append(correct_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'first_last_word_rule': 2294,\n",
       "         'hyphen_rule': 43,\n",
       "         'lower_case': 533,\n",
       "         'part_of_speach_rule': 13848})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(all_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "thefile = open('correct-headlines.txt', 'w',encoding='utf8')\n",
    "for item in new_headlines:\n",
    "    thefile.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
