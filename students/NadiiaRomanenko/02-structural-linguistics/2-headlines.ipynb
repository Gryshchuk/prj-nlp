{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formating\n",
    "\n",
    "[The Associated Press Stylebook](https://www.amazon.com/Associated-Press-Stylebook-2017-Briefing/dp/0465093043/) is a style guide widely used among American journalists. It enforces the following rules for capitalization of news headlines:\n",
    "\n",
    "1. Capitalize nouns, pronouns, adjectives, verbs, adverbs, and subordinate conjunctions. If a word is hyphenated, every part of the word should be capitalized (e.g., \"Self-Reflection\" not \"Self-reflection\").\n",
    "2. Capitalize the first and the last word.\n",
    "3. Lowercase all other parts of speech: articles, coordinating conjunctions, prepositions, particles, interjections.\n",
    "\n",
    "Write a program that formats a headline according to the rules above. Use any programming language and any NLP toolkit.\n",
    "\n",
    "When done, run your program on [the corpus of headlines from The Examiner](examiner-headlines.txt) and submit your program and a file with corrected headlines to your directory. Output statistics: how many titles were properly formatted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re, requests, pdb\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "url_headlines = 'https://raw.githubusercontent.com/vseloved/prj-nlp/master/tasks/02-structural-linguistics/examiner-headlines.txt'\n",
    "raw_headlines = requests.get(url_headlines).text.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_capitalize_pos = ['PROPN',\n",
    "                     'NOUN',\n",
    "                     'VERB',\n",
    "                     'ADJ',\n",
    "                     'ADV']\n",
    "\n",
    "to_capitalize_dep = ['mark']\n",
    "\n",
    "to_strip_space = ['PUNCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_headline(headline):\n",
    "    clean_headline = []\n",
    "    for token in nlp(headline):\n",
    "        \n",
    "        if re.match('[A-Z]{2,}', token.text):\n",
    "            proc_token = token.text_with_ws\n",
    "            \n",
    "        elif token.pos_ in to_capitalize_pos \\\n",
    "        or token.dep_ in to_capitalize_dep \\\n",
    "        or token.is_sent_start:\n",
    "            proc_token = token.text_with_ws.capitalize()\n",
    "            \n",
    "        else:\n",
    "            proc_token = token.text_with_ws.lower().replace('--', 'â€”')\n",
    "            \n",
    "        clean_headline.append(proc_token)\n",
    "        \n",
    "    if len(clean_headline) < 1:\n",
    "        pdb.set_trace()\n",
    "    clean_headline[-1] = clean_headline[-1].capitalize() \\\n",
    "                         if not re.match('[A-Z]', clean_headline[-1]) \\\n",
    "                         else clean_headline[-1]\n",
    "            \n",
    "    return ''.join(clean_headline).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('capitalized_examiner-headlines.txt', 'w') as f:\n",
    "    f.write('\\n'.join([clean_headline(h) for h in raw_headlines]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch catchy headlines\n",
    "\n",
    "The paper on [Automatic Extraction of News Values from Headline Text](http://www.aclweb.org/anthology/E17-4007) defines that a catchy headline has the following features:\n",
    "1. Prominence\n",
    "2. Sentiment\n",
    "3. Superlativeness\n",
    "4. Proximity\n",
    "5. Surprise\n",
    "6. Uniqueness\n",
    "\n",
    "Write a program that analyzes a headline for prominence (a.k.a, named entities), sentiment, and superlativeness. For sentiment, check if the average sentiment for the top 5 meanings of word+POS in [SentiWordNet](http://sentiwordnet.isti.cnr.it/) is above 0.5.\n",
    "\n",
    "When done, run your program on [the corpus of headlines](examiner-headlines.txt), extract the headlines that have at least one of the described features, and submit your program and a file with catchy headlines to your directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet\n",
    "from nltk.corpus.reader.wordnet import WordNetError\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prominent_ents = ['PERSON',\n",
    "                  'ORG',\n",
    "                  'PRODUCT',\n",
    "                  'WORK_OF_ART',]\n",
    "\n",
    "headline_prom = [len(list(filter(lambda t: t.ent_type_ in prominent_ents, nlp(headline))))\n",
    "                 for headline in raw_headlines]\n",
    "\n",
    "sent_pos_tags = {'NOUN': 'n',\n",
    "                 'VERB': 'v',\n",
    "                 'ADJ': 'a',\n",
    "                 'ADV': 'r',}\n",
    "\n",
    "def is_sentimental(headline):\n",
    "    nlp_headline = nlp(headline)\n",
    "    n_sentiment_words = 0\n",
    "    for t in nlp_headline:\n",
    "        if t.pos_ in sent_pos_tags:\n",
    "            for i in range(0, 5):\n",
    "                try:\n",
    "                    sentiments = sentiwordnet.senti_synset(f'{t.lemma_}.{sent_pos_tags[t.pos_]}.0{i}')\n",
    "                    if sentiments.neg_score() > 0.5 or sentiments.pos_score() > 0.5:\n",
    "                        n_sentiment_words += 1\n",
    "                except WordNetError:\n",
    "                    # in case word has < 5 sences\n",
    "                    return n_sentiment_words\n",
    "    return n_sentiment_words\n",
    "        \n",
    "headline_sentiments = list(map(is_sentimental, raw_headlines))\n",
    "\n",
    "headline_superl = [len(list(filter(lambda t: t.tag_ == 'JJS', nlp(headline))))\n",
    "                   for headline in raw_headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>prominent_w</th>\n",
       "      <th>sentimental_w</th>\n",
       "      <th>superlative_w</th>\n",
       "      <th>is_catchy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>Best National Hispanic Heritage Month of Jazz ...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>Sarasota Orchestra's World premiere of 'Salon ...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>Justin Gardenhire Wins Event 11 at WSOPC New O...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>Grammy Week: Rev Run, RedOne and DJ Khaled for...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>Golden Globes Red Carpet 'How Tos' With Pravan...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline  prominent_w  \\\n",
       "1641  Best National Hispanic Heritage Month of Jazz ...           12   \n",
       "2853  Sarasota Orchestra's World premiere of 'Salon ...           14   \n",
       "2025  Justin Gardenhire Wins Event 11 at WSOPC New O...           13   \n",
       "4410  Grammy Week: Rev Run, RedOne and DJ Khaled for...           13   \n",
       "4564  Golden Globes Red Carpet 'How Tos' With Pravan...           11   \n",
       "\n",
       "      sentimental_w  superlative_w  is_catchy  \n",
       "1641              4              1         17  \n",
       "2853              0              0         14  \n",
       "2025              0              0         13  \n",
       "4410              0              0         13  \n",
       "4564              2              0         13  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_stats = pd.DataFrame({'headline': raw_headlines,\n",
    "                               'prominent_w': headline_prom,\n",
    "                               'sentimental_w': headline_sentiments,\n",
    "                               'superlative_w': headline_superl,\n",
    "                              })\n",
    "\n",
    "headline_stats['is_catchy'] = headline_stats.sum(axis=1, numeric_only=True)\n",
    "headline_stats = headline_stats.sort_values('is_catchy', ascending=False)\n",
    "\n",
    "headline_stats.loc[headline_stats.superlative_w > 0\n",
    "                  ].to_html('catchy_examiner-headlines.md')\n",
    "\n",
    "headline_stats.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
