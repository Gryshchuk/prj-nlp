{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import (roc_auc_score, precision_score, recall_score, \n",
    "                             confusion_matrix, accuracy_score, f1_score,\n",
    "                             classification_report)\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import xgboost as xgb\n",
    "from pathlib import Path\n",
    "from tokenize_uk.tokenize_uk import tokenize_words\n",
    "from operator import itemgetter\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport config\n",
    "from config import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, pred, proba=None, labels=[\"1\", \"2\", \"3\", \"4\", \"5\"], print_=True,\n",
    "                 average=\"macro\", report=True):\n",
    "    output = {}\n",
    "    if proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, proba)\n",
    "        output[\"AUC\"] = roc_auc\n",
    "    output[\"Recall\"] = recall_score(y_test, pred, average=average)\n",
    "    output[\"Precision\"] = precision_score(y_test, pred, average=average)\n",
    "    output[\"F1\"] = f1_score(y_test, pred, average=average)\n",
    "    output[\"accuracy\"] = accuracy_score(y_test, pred)\n",
    "    if labels is not None:\n",
    "        index = labels\n",
    "        columns = [\"pred_\" + el for el in index]\n",
    "    else:\n",
    "        columns = None\n",
    "        index = None\n",
    "    output[\"conf_matrix\"] = pd.DataFrame(confusion_matrix(y_test, pred), \n",
    "                                         columns=columns, index=index)\n",
    "    if print_:\n",
    "        for key, value in output.items():\n",
    "            if \"matrix\" in key:\n",
    "                print(value)\n",
    "            else:\n",
    "                print(f\"{key}: {value:0.3f}\")\n",
    "    if report:\n",
    "        output[\"report\"] = classification_report(y_test, pred, labels)\n",
    "        print(output[\"report\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stop_words.txt\") as file:\n",
    "    stop = file.readlines()\n",
    "stop = [el.strip() for el in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone = pd.read_csv(\"tone-dict.tsv\", sep='\\t', header=None, names=[\"word\", \"sentiment\"])\n",
    "tone[\"word\"] = tone[\"word\"].str.lower()\n",
    "tone_map = tone.set_index(\"word\").to_dict()[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in Path().glob(\"smart*.json\"):\n",
    "    with open(file, \"r\") as f_in:\n",
    "        data.extend(json.load(f_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_normalize(data, record_path=\"reviews\", meta=[\"path\", \"price\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df.apply(lambda x: x['text'] + \" \" + x['pros']+ \" \" + x['cons'], axis=1)\n",
    "#frq = df.groupby(\"stars\")[\"text\"].count()\n",
    "#df[\"weights\"] = df[\"stars\"].map({\"1\": 1, \"2\": 1, \"3\": 1, \"4\": 5, \"5\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>cons</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>pros</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>path</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>балацька лариса</td>\n",
       "      <td>До телефона треба зразу брати і захисник скло ...</td>\n",
       "      <td>2018-3-24</td>\n",
       "      <td>https://rozetka.com.ua/zte_blade_v8_gray/p2573...</td>\n",
       "      <td>Камера і батарея</td>\n",
       "      <td>5</td>\n",
       "      <td>Купили телефон в подарунок дітям, зразу два зо...</td>\n",
       "      <td>[Интернет-супермаркет №, Смартфоны, ТВ и элект...</td>\n",
       "      <td>4499</td>\n",
       "      <td>ZTE Blade V8 Gray</td>\n",
       "      <td>Купили телефон в подарунок дітям, зразу два зо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                               cons  \\\n",
       "0  балацька лариса  До телефона треба зразу брати і захисник скло ...   \n",
       "\n",
       "        date                                               link  \\\n",
       "0  2018-3-24  https://rozetka.com.ua/zte_blade_v8_gray/p2573...   \n",
       "\n",
       "               pros  stars                                               text  \\\n",
       "0  Камера і батарея      5  Купили телефон в подарунок дітям, зразу два зо...   \n",
       "\n",
       "                                                path  price  \\\n",
       "0  [Интернет-супермаркет №, Смартфоны, ТВ и элект...   4499   \n",
       "\n",
       "               title                                             review  \n",
       "0  ZTE Blade V8 Gray  Купили телефон в подарунок дітям, зразу два зо...  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "count    3797.000000\n",
       "mean        4.359494\n",
       "std         1.004769\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         5.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)\n",
    "df[\"stars\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2293</td>\n",
       "      <td>0.603898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>988</td>\n",
       "      <td>0.260205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>0.063998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "      <td>0.036608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>0.035291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars     stars\n",
       "5   2293  0.603898\n",
       "4    988  0.260205\n",
       "3    243  0.063998\n",
       "1    139  0.036608\n",
       "2    134  0.035291"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df.stars.value_counts()\n",
    "pd.concat([s, s / s.sum()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we deal with an imbalanced multiclass classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               700\n",
       "Немає           92\n",
       "немає           85\n",
       "-               34\n",
       "не виявлено     31\n",
       "Не виявлено     20\n",
       "нема            20\n",
       "Відсутні        19\n",
       "Не виявила      16\n",
       "Нема            15\n",
       "Name: cons, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.088316467341306"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.700239808153477"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze cons\n",
    "df[\"cons\"].value_counts().head(10)\n",
    "patt = \"не має|не знайш|немає|не вияв|відсутн|нема|--\"\n",
    "cond = ((df[\"cons\"].str.lower().str.contains(patt, regex=True)) | (df[\"cons\"]==\"\"))\n",
    "df.loc[~cond, \"stars\"].mean()\n",
    "df.loc[cond, \"stars\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  626\n",
       "Ціна               27\n",
       "ціна               13\n",
       "Дизайн              7\n",
       "дешевий             6\n",
       "Ціна-якість         5\n",
       "Дешевий             5\n",
       "Тиха                5\n",
       "Ціна та якість      5\n",
       "немає               5\n",
       "Name: pros, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.465476749647722"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.436102236421725"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze pros\n",
    "df[\"pros\"].value_counts().head(10)\n",
    "patt = \"ціна|якість\"\n",
    "cond1 = (df[\"pros\"].str.lower().str.contains(patt, regex=True)) | (df[\"pros\"].str.len() < 10)\n",
    "cond2 = df[\"pros\"]==\"\"\n",
    "cond = cond2\n",
    "df.loc[~cond, \"stars\"].mean()\n",
    "df.loc[cond, \"stars\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 20% of data for testing and stratify according to the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 3037, Num. of test: 760\n"
     ]
    }
   ],
   "source": [
    "y = df[\"stars\"]\n",
    "X = df.loc[:, ~df.columns.isin([\"stars\"])]\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate performance of the very simple baseline prediction algorithm - <b>everything is a 5 star review (just take a majority class)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.604\n",
      "Precision: 0.365\n",
      "F1: 0.455\n",
      "accuracy: 0.604\n",
      "   pred_1  pred_2  pred_3  pred_4  pred_5\n",
      "1       0       0       0       0      28\n",
      "2       0       0       0       0      27\n",
      "3       0       0       0       0      48\n",
      "4       0       0       0       0     198\n",
      "5       0       0       0       0     459\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00        28\n",
      "          2       0.00      0.00      0.00        27\n",
      "          3       0.00      0.00      0.00        48\n",
      "          4       0.00      0.00      0.00       198\n",
      "          5       0.60      1.00      0.75       459\n",
      "\n",
      "avg / total       0.36      0.60      0.45       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_pred = np.full(y_test.shape, 5)\n",
    "base_metrics = calc_metrics(y_test, base_pred, proba=None, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF - IDF & other fesatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_array(x):\n",
    "    if len(x) > 0:\n",
    "        return x\n",
    "    return np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x = validate_array(np.array(x))\n",
    "    nonzero = np.nonzero(x)[0].shape[0]\n",
    "    n_pos = (x > 0).sum()\n",
    "    n_neg = (x < 0).sum()\n",
    "    pos = validate_array(x[x > 0])\n",
    "    neg = validate_array(x[x < 0])\n",
    "    max_pos = np.max(pos)\n",
    "    min_pos = np.min(pos)\n",
    "    mean_pos = np.mean(pos)\n",
    "    std_pos = np.std(pos)\n",
    "    sum_pos = np.sum(pos)\n",
    "    max_neg = np.max(neg)\n",
    "    min_neg = np.min(neg)\n",
    "    mean_neg = np.mean(neg)\n",
    "    std_neg = np.std(neg)\n",
    "    sum_neg = np.sum(neg)\n",
    "    return pd.Series({\"nonzero\": nonzero, \n",
    "                      \"nonzero_ratio\": nonzero / len(x) if len(x)>0 else 0,\n",
    "                      \"n_pos\": n_pos,\n",
    "                      \"n_pos_ratio\": n_pos / nonzero if nonzero>0 else 0,\n",
    "                      \"n_neg\": n_neg,\n",
    "                      \"n_neg_ratio\": n_neg / nonzero if nonzero>0 else 0,\n",
    "                      \"mean\": np.mean(x),\n",
    "                      \"max\": np.max(x),\n",
    "                      \"min\": np.min(x),\n",
    "                      \"std\": np.std(x),\n",
    "                      \"sum\": np.sum(x),\n",
    "                      \"max_pos\": max_pos,\n",
    "                      \"min_pos\": min_pos,\n",
    "                      \"mean_pos\": mean_pos,\n",
    "                      \"std_pos\": std_pos,\n",
    "                      \"sum_pos\": sum_pos,\n",
    "                      \"max_neg\": max_neg,\n",
    "                      \"min_neg\": min_neg,\n",
    "                      \"mean_neg\": mean_neg,\n",
    "                      \"std_neg\": std_neg,\n",
    "                      \"sum_neg\": sum_neg \n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_cons(df, var=\"cons\", patt=\"не має|не знайш|немає|не вияв|відсутн|нема|--\"):\n",
    "    cond = ((df[var].str.lower().str.contains(patt, regex=True)) | (df[var]==\"\"))\n",
    "    return cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tone(X, tone_map=tone_map, var=\"review\"):\n",
    "    temp = X[var].map(lambda x: [tone_map.get(word.lower(), 0) for word in tokenize_words(x)])\n",
    "    return temp.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformer(train, test, transformer):\n",
    "    if transformer is not None:\n",
    "        train = transformer.fit_transform(train)\n",
    "        test = transformer.transform(test)\n",
    "        return train, test\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(X_train, X_test, transformer=None, var=\"review\", features=None,\n",
    "                   vectorizer=None):\n",
    "    f_train = []\n",
    "    f_test = []\n",
    "    for feature in features:\n",
    "        if feature == \"tfidf\":\n",
    "            train = vectorizer.fit_transform(X_train[var]).toarray()\n",
    "            test = vectorizer.transform(X_test[var]).toarray()\n",
    "            f_train.append(train)\n",
    "            f_test.append(test)\n",
    "        elif feature == \"sentiment\":\n",
    "            train = add_tone(X_train, var=var).values\n",
    "            test = add_tone(X_test, var=var).values\n",
    "            train, test = apply_transformer(train, test, transformer)\n",
    "            f_train.append(train)\n",
    "            f_test.append(test)\n",
    "        elif feature == \"len\":\n",
    "            train = X_train[[\"text\", \"pros\", \"cons\"]].applymap(len).values\n",
    "            test = X_test[[\"text\", \"pros\", \"cons\"]].applymap(len).values\n",
    "            train, test = apply_transformer(train, test, transformer)\n",
    "            f_train.append(train)\n",
    "            f_test.append(test)\n",
    "        elif feature == \"is_cons\":\n",
    "            train = condition_cons(X_train).astype(int)[:, np.newaxis]\n",
    "            test = condition_cons(X_test).astype(int)[:, np.newaxis]\n",
    "            f_train.append(train)\n",
    "            f_test.append(test)\n",
    "    return np.concatenate((f_train), axis=1), np.concatenate((f_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nb(train, y_train, test, y_test, alpha=2.5, priors=None):\n",
    "    clf = MultinomialNB(alpha=alpha, class_prior=priors)\n",
    "    clf.fit(train, y_train)\n",
    "    pred = clf.predict(test)\n",
    "    proba = clf.predict_proba(test)\n",
    "    metrics = calc_metrics(y_test, pred, proba=None, average=\"weighted\")\n",
    "    return pred, proba, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = QuantileTransformer(n_quantiles=10, output_distribution=\"uniform\")\n",
    "minmax = MinMaxScaler()\n",
    "std = StandardScaler()\n",
    "maxabs = MaxAbsScaler()\n",
    "transformer = minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try only TF-IDF (with stop words if we use analyzer=word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 3500\n"
     ]
    }
   ],
   "source": [
    "tf_params = {\"lowercase\": 1,\n",
    "             \"analyzer\": \"word\",\n",
    "             \"stop_words\": stop,\n",
    "             \"ngram_range\": (1, 1),\n",
    "             \"min_df\": 1,\n",
    "             \"max_df\": 1.0,\n",
    "             \"preprocessor\": None,\n",
    "             \"max_features\": 3500*1 or None,\n",
    "             \"norm\": 'l2'*0,\n",
    "             \"use_idf\": 0,\n",
    "             \"smooth_idf\": 0,\n",
    "             \"sublinear_tf\": 0, \n",
    "             \"tokenizer\": None#tokenize_words\n",
    "             }\n",
    "var = \"review\"\n",
    "features = [\n",
    "            \"tfidf\",\n",
    "            #\"sentiment\", \n",
    "            #\"len\", \n",
    "            #\"is_cons\"\n",
    "            ]\n",
    "vectorizer = TfidfVectorizer(**tf_params)\n",
    "train, test = build_features(X_train, X_test, features=features, vectorizer=vectorizer,\n",
    "                            transformer=transformer, var=var)\n",
    "print(f\"Features: {train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.634\n",
      "Precision: 0.561\n",
      "F1: 0.586\n",
      "accuracy: 0.634\n",
      "   pred_1  pred_2  pred_3  pred_4  pred_5\n",
      "1       2       0       2      13      11\n",
      "2       1       0       3      13      10\n",
      "3       2       0       1      27      18\n",
      "4       0       0       4      73     121\n",
      "5       0       1       1      51     406\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.07      0.12        28\n",
      "          2       0.00      0.00      0.00        27\n",
      "          3       0.09      0.02      0.03        48\n",
      "          4       0.41      0.37      0.39       198\n",
      "          5       0.72      0.88      0.79       459\n",
      "\n",
      "avg / total       0.56      0.63      0.59       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred, proba, metrics = fit_nb(train, y_train, test, y_test, alpha=2.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's add sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 3521\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "            \"tfidf\",\n",
    "            \"sentiment\", \n",
    "            #\"len\", \n",
    "            #\"is_cons\"\n",
    "            ]\n",
    "train, test = build_features(X_train, X_test, features=features, vectorizer=vectorizer,\n",
    "                            transformer=transformer, var=var)\n",
    "print(f\"Features: {train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.646\n",
      "Precision: 0.558\n",
      "F1: 0.586\n",
      "accuracy: 0.646\n",
      "   pred_1  pred_2  pred_3  pred_4  pred_5\n",
      "1       1       0       2      11      14\n",
      "2       1       0       2      15       9\n",
      "3       0       0       0      30      18\n",
      "4       0       0       0      68     130\n",
      "5       0       0       0      37     422\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.04      0.07        28\n",
      "          2       0.00      0.00      0.00        27\n",
      "          3       0.00      0.00      0.00        48\n",
      "          4       0.42      0.34      0.38       198\n",
      "          5       0.71      0.92      0.80       459\n",
      "\n",
      "avg / total       0.56      0.65      0.59       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred, proba, metrics = fit_nb(train, y_train, test, y_test, alpha=2.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['num_class'] = df[\"stars\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, y_train-1)#, weight=X_train[\"weights\"])\n",
    "dtest = xgb.DMatrix(test, y_test-1)#, weight=X_test[\"weights\"])\n",
    "eval_set = [(dtrain, \"train\"), (dtest, \"eval\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.50738\ttrain-merror:0.325771\teval-mlogloss:1.50779\teval-merror:0.333938\n",
      "Multiple eval metrics have been passed: 'eval-merror' will be used for early stopping.\n",
      "\n",
      "Will train until eval-merror hasn't improved in 50 rounds.\n",
      "[50]\ttrain-mlogloss:0.847278\ttrain-merror:0.323503\teval-mlogloss:0.87719\teval-merror:0.319419\n",
      "[100]\ttrain-mlogloss:0.825416\ttrain-merror:0.317151\teval-mlogloss:0.865001\teval-merror:0.317604\n",
      "Stopping. Best iteration:\n",
      "[52]\ttrain-mlogloss:0.845629\ttrain-merror:0.323049\teval-mlogloss:0.875408\teval-merror:0.315789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(dtrain=dtrain, num_boost_round=params.get(\"n_estimators\"), \n",
    "                  early_stopping_rounds=params.get(\"early_stopping_rounds\"), \n",
    "                  params=params, evals=eval_set, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (accuracy): 0.684211\n",
      "Recall: 0.679\n",
      "Precision: 0.564\n",
      "F1: 0.605\n",
      "accuracy: 0.679\n",
      "   pred_1  pred_2  pred_3  pred_4  pred_5\n",
      "1       0       0       0      10       9\n",
      "2       0       0       0       5       8\n",
      "3       0       0       0       7      24\n",
      "4       0       0       0      26      96\n",
      "5       0       0       0      18     348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00        19\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.00      0.00      0.00        31\n",
      "          4       0.39      0.21      0.28       122\n",
      "          5       0.72      0.95      0.82       366\n",
      "\n",
      "avg / total       0.56      0.68      0.60       551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_xgb = (model.predict(dtest)+1).astype(int)\n",
    "print(f\"Best score (accuracy): {1-model.best_score}\")\n",
    "xgb_metrics = calc_metrics(y_test, pred_xgb, average=\"weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
