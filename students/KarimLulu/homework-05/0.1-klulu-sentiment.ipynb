{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import (roc_auc_score, precision_score, recall_score, \n",
    "                             confusion_matrix, accuracy_score, f1_score,\n",
    "                             classification_report)\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stop_words.txt\") as f:\n",
    "    stop = f.readlines()\n",
    "stop = [el.strip() for el in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, pred, proba=None, labels=[\"1\", \"2\", \"3\", \"4\", \"5\"], print_=True,\n",
    "                 average=\"macro\", report=True):\n",
    "    output = {}\n",
    "    if proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, proba)\n",
    "        output[\"AUC\"] = roc_auc\n",
    "    output[\"Recall\"] = recall_score(y_test, pred, average=average)\n",
    "    output[\"Precision\"] = precision_score(y_test, pred, average=average)\n",
    "    output[\"F1\"] = f1_score(y_test, pred, average=average)\n",
    "    output[\"accuracy\"] = accuracy_score(y_test, pred)\n",
    "    if labels is not None:\n",
    "        index = labels\n",
    "        columns = [\"pred_\" + el for el in index]\n",
    "    else:\n",
    "        columns = None\n",
    "        index = None\n",
    "    output[\"conf_matrix\"] = pd.DataFrame(confusion_matrix(y_test, pred), \n",
    "                                         columns=columns, index=index)\n",
    "    if print_:\n",
    "        for key, value in output.items():\n",
    "            if \"matrix\" in key:\n",
    "                print(value)\n",
    "            else:\n",
    "                print(f\"{key}: {value:0.3f}\")\n",
    "    if report:\n",
    "        print(classification_report(y_test, pred, labels))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"items.jl\"\n",
    "with open(filename, \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_normalize(data, record_path=\"reviews\", meta=[\"path\", \"price\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df.apply(lambda x: x['text'] + \" \" + x['pros']+ \" \" + x['cons'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>cons</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>pros</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>path</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Наталка</td>\n",
       "      <td>не виявили</td>\n",
       "      <td>2016-7-07</td>\n",
       "      <td>https://bt.rozetka.com.ua/2030437/p2030437/com...</td>\n",
       "      <td>Якісний вироб, доступна ціна</td>\n",
       "      <td>5</td>\n",
       "      <td>Чудова морозильна камера.Придбали ще взимку, в...</td>\n",
       "      <td>[Интернет-супермаркет №, Бытовая техника, инте...</td>\n",
       "      <td>11199</td>\n",
       "      <td>Встраиваемая морозильная камера Freggia LSB0010</td>\n",
       "      <td>Чудова морозильна камера.Придбали ще взимку, в...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    author        cons       date  \\\n",
       "0  Наталка  не виявили  2016-7-07   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://bt.rozetka.com.ua/2030437/p2030437/com...   \n",
       "\n",
       "                           pros  stars  \\\n",
       "0  Якісний вироб, доступна ціна      5   \n",
       "\n",
       "                                                text  \\\n",
       "0  Чудова морозильна камера.Придбали ще взимку, в...   \n",
       "\n",
       "                                                path  price  \\\n",
       "0  [Интернет-супермаркет №, Бытовая техника, инте...  11199   \n",
       "\n",
       "                                             title  \\\n",
       "0  Встраиваемая морозильная камера Freggia LSB0010   \n",
       "\n",
       "                                              review  \n",
       "0  Чудова морозильна камера.Придбали ще взимку, в...  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "count    2755.000000\n",
       "mean        4.458802\n",
       "std         0.956587\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         5.000000\n",
       "75%         5.000000\n",
       "max         5.000000\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)\n",
    "df[\"stars\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1832</td>\n",
       "      <td>0.664973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "      <td>0.221416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>0.055535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>0.023593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars     stars\n",
       "5   1832  0.664973\n",
       "4    610  0.221416\n",
       "3    153  0.055535\n",
       "1     95  0.034483\n",
       "2     65  0.023593"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df.stars.value_counts()\n",
    "pd.concat([s, s / s.sum()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               700\n",
       "Немає           92\n",
       "немає           85\n",
       "-               34\n",
       "не виявлено     31\n",
       "Не виявлено     20\n",
       "нема            20\n",
       "Відсутні        19\n",
       "Не виявила      16\n",
       "Нема            15\n",
       "Name: cons, dtype: int64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.088316467341306"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.700239808153477"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze cons\n",
    "df[\"cons\"].value_counts().head(10)\n",
    "patt = \"не має|не знайш|немає|не вияв|відсутн|нема|--\"\n",
    "cond = ((df[\"cons\"].str.lower().str.contains(patt, regex=True)) | (df[\"cons\"]==\"\"))\n",
    "df.loc[~cond, \"stars\"].mean()\n",
    "df.loc[cond, \"stars\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_cons\"] = cond.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  626\n",
       "Ціна               27\n",
       "ціна               13\n",
       "Дизайн              7\n",
       "дешевий             6\n",
       "Ціна та якість      5\n",
       "+                   5\n",
       "Ціна-якість         5\n",
       "немає               5\n",
       "Тиха                5\n",
       "Name: pros, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.465476749647722"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.436102236421725"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze pros\n",
    "df[\"pros\"].value_counts().head(10)\n",
    "patt = \"ціна|якість\"\n",
    "cond1 = (df[\"pros\"].str.lower().str.contains(patt, regex=True)) | (df[\"pros\"].str.len() < 10)\n",
    "cond2 = df[\"pros\"]==\"\"\n",
    "cond = cond2\n",
    "df.loc[~cond, \"stars\"].mean()\n",
    "df.loc[cond, \"stars\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 2204, Num. of test: 551\n"
     ]
    }
   ],
   "source": [
    "y = df[\"stars\"]\n",
    "X = df.loc[:, ~df.columns.isin([\"stars\"])]\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = QuantileTransformer(n_quantiles=10, output_distribution=\"uniform\")\n",
    "minmax = MinMaxScaler()\n",
    "std = StandardScaler()\n",
    "maxabs = MaxAbsScaler()\n",
    "transformer = maxabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(train, X, type_=\"train\", transformer=None):\n",
    "    is_cons = X[\"is_cons\"].values[:, np.newaxis]\n",
    "    if type_ == \"train\":\n",
    "        func = transformer.fit_transform\n",
    "    else:\n",
    "        func = transformer.transform\n",
    "    len_text = func(X[\"text\"].map(len).values[:, np.newaxis])\n",
    "    len_pros = func(X[\"pros\"].map(len).values[:, np.newaxis])\n",
    "    len_cons = func(X[\"cons\"].map(len).values[:, np.newaxis])\n",
    "    return np.concatenate((train, is_cons, len_text, len_pros, len_cons), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_params = {\"lowercase\": 1,\n",
    "             \"analyzer\": \"word\",\n",
    "             \"stop_words\": stop,\n",
    "             \"ngram_range\": (1, 1),\n",
    "             \"min_df\": 1,\n",
    "             \"max_df\": 1.0,\n",
    "             \"preprocessor\": None,\n",
    "             \"max_features\": 4500,\n",
    "             \"norm\": 'l2'*0,\n",
    "             \"use_idf\": 0,\n",
    "             \"smooth_idf\": 0,\n",
    "             \"sublinear_tf\": 0\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 4500\n"
     ]
    }
   ],
   "source": [
    "var = \"review\"\n",
    "vectorizer = TfidfVectorizer(**tf_params)\n",
    "train = vectorizer.fit_transform(X_train[var]).toarray()\n",
    "test = vectorizer.transform(X_test[var]).toarray()\n",
    "print(f\"Features: {len(vectorizer.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_features(train, X_train, \"train\", transformer)#[:, -2:]\n",
    "test = add_features(test, X_test, \"test\", transformer)#[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=2, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.693\n",
      "Precision: 0.624\n",
      "F1: 0.615\n",
      "accuracy: 0.693\n",
      "   pred_1  pred_2  pred_3  pred_4  pred_5\n",
      "1       1       0       1       6      11\n",
      "2       0       0       0       6       7\n",
      "3       0       0       1       6      24\n",
      "4       1       0       0      23      98\n",
      "5       0       0       0       9     357\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.05      0.10        19\n",
      "          2       0.00      0.00      0.00        13\n",
      "          3       0.50      0.03      0.06        31\n",
      "          4       0.46      0.19      0.27       122\n",
      "          5       0.72      0.98      0.83       366\n",
      "\n",
      "avg / total       0.62      0.69      0.62       551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=2)#, class_prior=[0.2]*5)\n",
    "#clf = GaussianNB([0.2]*5)\n",
    "clf.fit(train, y_train)\n",
    "pred = clf.predict(test)\n",
    "proba = clf.predict_proba(test)\n",
    "metrics = calc_metrics(y_test, pred, proba=None, average=\"weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
